---
title: "VITON: An Image-based Virtual Try-on Network" 논문 정리
excerpt: "Virtual TryOn 의 첫 번째 논문 읽기, CVPR 2018"

categories:
   - deep-learning
tags:
   - VITON

use_math: true
---

# 2D Image-based Virtual Try-on Network

Virtual Try-on 논문을 접한 첫 번째 논문이다. 누가 VITON이 좀 '짜치다' 라고 표현했는데 무슨 뜻인지 알거 같다. 엄청 이래저래 모델을 붙여서 만들었다. (Image-inpainting 같은 GAN 모델들이 좀 그런 케이스가 많다.) 그래서 솔직히 말하면 좀 엄청 좋은 논문 같지는 않고, 처음 2D 이미지를 가지고 옷을 입혔다는 면에서 contribution 이 있는 것 같다. 그래서 아주 간략하게 포스팅 하려고 한다..

---
<img src="https://user-images.githubusercontent.com/43398106/146874595-cd911304-9efe-4fe7-8b11-3a7554961e12.png" width="500">

## Virtual Try-On 이란? 
위에 그림처럼 사람 이미지와 옷 이미지가 주어졌을 때, 사람의 포즈나 각도 등 다른 요소는 유지하면서 옷만 바뀌어 입도록 하는 task 다. 

## An Overview of VITON 

<img src="https://user-images.githubusercontent.com/43398106/146875025-3723a15d-cdd8-43d9-a6f7-a1917de68eb9.png" >

Input으로는 Target Clothing *c* 와 Person Representation *p* 가 주어진다. *p*는 사람 이미지에서 추출한 3개의 정보이고 이들을 행으로 묶어서 Coarse network *G_c* 를 통과해 보다 막연한 이미지 *I*' 와 clothing mask *M* 을 생성한다. 그리고 이를 다시 Refinement network *G_r* 를 통과시켜 보다 더 샤프하고 정교한 이미지를 만들어낸다. 

## 1. Person Representation
<img src="https://user-images.githubusercontent.com/43398106/146875230-5ad4d314-68a1-4f79-8751-09abacbb5018.png" >

Input 으로 들어갈 *p* 는 총 3개의 정보를 갖게 된다. 